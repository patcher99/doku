---
title: What is Doku?
description: 'Open-source platform for monitoring and evaluating LLMs at scale'
---

<iframe
  width="560"
  height="315"
  src="https://www.youtube.com/embed/6jhxVesllEY?si=M8dkLVVE2G7WhmBo"
  title="Demo: Monitoring LLM Application with Doku"
  frameborder="0"
  allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; playsinline"
  allowfullscreen
></iframe>

Doku is an **open-source LLMOps tool** engineered to enables developers with comprehensive capabilities to monitor, analyze, and optimize LLM applications. It provides valuable real-time data on **LLM usage, performance, and costs**. Through seamless integrations with leading LLM platforms, including OpenAI, Cohere, and Anthropic, Doku acts as a central command center for all your LLM needs. It effectively guides your efforts, ensuring that your LLM applications not only operate at peak efficiency but also scale successfully.

## Why use Doku?
Get advanced monitoring and evaluation for your LLM applications with these key benefits:

- **Granular Usage Insights of your LLM Applications**: Assess your LLM's performance and costs with fine-grained control, breaking down metrics by environment (such as staging or production) or application, to optimize for efficiency and scalability.
- **Real-Time Data Streaming**: Unlike other platforms where you might wait minutes to see your data due to data being sent in batches, Doku is able to display data as it streams. This immediate insight enables quick decision-making and adjustments.
- **Zero Added Latency**: Doku's smart data handling ensures rapid data processing without impacting your application's performance, maintaining the responsiveness of your LLM applications.
- **Connect to Observability Platforms**: Doku seamlessly connects with leading observability platforms like Grafana Cloud and Datadog, among others to automatically export data. 

## How it works
<Frame>
  <img src="https://raw.githubusercontent.com/dokulabs/.github/main/profile/assets/banner.gif" />
</Frame>

### Step 1: Instrument your Application
Integrating the `dokumetry` SDK into LLM applications is straightforward with SDKs designed for Python and NodeJS. Start monitoring for your LLM Application with just **two lines of code**: 

<CodeGroup>
```python python
import dokumetry

dokumetry.init(llm=openai, doku_url="YOUR_DOKU_INGESTER_URL", api_key="YOUR_DOKU_TOKEN")
```

```javascript NodeJS
import DokuMetry from 'dokumetry';

DokuMetry.init({llm: openai, dokuUrl: "YOUR_DOKU_INGESTER_URL", apiKey: "YOUR_DOKU_TOKEN"})
```
</CodeGroup>

### Step 2: Data processed by Doku Ingester
Once the `dokumetry` SDKs are configured in your LLM application, Monitoring data starts streaming to the [Doku Ingester](https://github.com/dokulabs/doku/tree/main/src/ingester#readme). It processes and safely stores your data in ClickHouse, keeping your LLM Monitoring data **secure** and **compliant** in your environment.

You can choose to use a new ClickHouse database setup or connect to your existing one to work with Doku. 

### Step 3: Visualize and analyze
With your LLM monitoring data processed and securely stored, you can now leverage the Doku UI for in-depth visualization and analysis. Doku UI allows you to explore LLM costs, token usage, performance metrics, and user interactions in an intuitive interface. This powerful tool enhances your ability to observe and optimize your LLM applications, ensuring you make data-driven decisions for improvement.

<Frame>
    <img src="https://github.com/dokulabs/.github/blob/main/profile/assets/doku-client-1.jpg?raw=true" />
    <img src="https://github.com/dokulabs/.github/blob/main/profile/assets/doku-client-2.jpg?raw=true" />
    <img src="https://github.com/dokulabs/.github/blob/main/profile/assets/doku-client-3.jpg?raw=true" />
</Frame>

For those with a preferred observability platform, you can also integrate and visualize this data elsewhere with ease. This flexibility ensures optimal monitoring workflow integration, regardless of your platform choice. For more details on how to set up these connections, check out the [Connections](https://example.com/0.1/connections/intro) guide.
## Getting Started
Select from the following guides to learn more about how to use Doku:

<CardGroup cols={2}>
<Card title="Quickstart" href="/0.1/quickstart" icon='bolt'>
Get Started with monitoring your LLM Applications in 2 simple steps
</Card>
<Card title="Integrations" href="/0.1/integrations/introduction" icon='circle-nodes'>
Integrate your LLM Provider with Doku 
</Card>
<Card title="Installation" href="/0.1/installation" icon='circle-down'>
Deploy Doku in your preferred environment 
</Card>
<Card title="Connections" href="/0.1/connections/intro" icon='link'>
Connect to your existing Observablity Platform
</Card>
</CardGroup>